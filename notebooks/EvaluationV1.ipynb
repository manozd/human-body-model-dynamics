{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "placed-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "import argparse\n",
    "from ddpg_torch.ddpg_torch import Agent\n",
    "import gym\n",
    "import numpy as np\n",
    "from lifting_rl.linkage_env import LinkageEnv\n",
    "\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "governing-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"N_LINKS\": 5,\n",
    "    \"PARAM_VALS\": np.array([9.81], dtype=np.float32),\n",
    "    \"OBS_LOW\": np.array([0.5, 1, -0.5, -2.5, -2], dtype=np.float32),\n",
    "    \"OBS_HIGH\": np.array([2.5, 3.1, 2.2, -0.3, -0.2], dtype=np.float32),\n",
    "    \"SPEED_LIMIT\": 8,\n",
    "    \"ACT_LIMIT\": 100,\n",
    "    \"TIME_STEP\": 0.01,\n",
    "    \"VIDEO_FPS\": 30,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "later-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space:  Box(10,)\n",
      "action_space:  Box(5,)\n"
     ]
    }
   ],
   "source": [
    "env = LinkageEnv(params, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powerful-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    lr_actor=0.000025,\n",
    "    lr_critic=0.00025,\n",
    "    input_dims=[25],\n",
    "    tau=0.001,\n",
    "    env=env,\n",
    "    batch_size=64,\n",
    "    layer1_size=400,\n",
    "    layer2_size=300,\n",
    "    n_actions=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_models()\n",
    "for i in range(100000):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = np.array([1.4993861662461676,1.6887208408893308,1.5188663851286528,-1.4618884620583108,\n",
    "                      -1.2326123593367506, 0, 0, 0, 0, 0], dtype=np.float32)\n",
    "    gpos = np.array([1.2902978932031173,2.356563938016626,0.21031300459884766,-1.7127402937960399,-1.2724807073392603], dtype=np.float32)\n",
    "    obs = env.inference_reset(state, gpos)\n",
    "    while not done:\n",
    "        env.render()\n",
    "        act = agent.choose_action(obs)\n",
    "        new_state, reward, done, info = env.step(act)\n",
    "        print(act)\n",
    "        score += reward\n",
    "        obs = new_state\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-federal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
